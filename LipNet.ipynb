{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
   "metadata": {
    "editable": true,
    "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
    "tags": []
   },
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ni0KA3RDVbC4",
   "metadata": {
    "id": "ni0KA3RDVbC4"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddfbccbe-41ae-4c23-98b1-a13868e2b499",
   "metadata": {
    "id": "ddfbccbe-41ae-4c23-98b1-a13868e2b499",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------------\n",
      "absl-py                      2.1.0\n",
      "anyio                        4.2.0\n",
      "argon2-cffi                  23.1.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.3.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "async-lru                    2.0.4\n",
      "attrs                        23.2.0\n",
      "Babel                        2.14.0\n",
      "beautifulsoup4               4.12.3\n",
      "bleach                       6.1.0\n",
      "cachetools                   5.3.2\n",
      "certifi                      2023.11.17\n",
      "cffi                         1.16.0\n",
      "charset-normalizer           3.3.2\n",
      "comm                         0.2.1\n",
      "contourpy                    1.2.0\n",
      "cycler                       0.12.1\n",
      "debugpy                      1.8.0\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "executing                    2.0.1\n",
      "fastjsonschema               2.19.1\n",
      "filelock                     3.13.1\n",
      "flatbuffers                  23.5.26\n",
      "fonttools                    4.47.2\n",
      "fqdn                         1.5.1\n",
      "gast                         0.5.4\n",
      "gdown                        4.7.3\n",
      "google-auth                  2.26.2\n",
      "google-auth-oauthlib         1.2.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.60.0\n",
      "h5py                         3.10.0\n",
      "idna                         3.6\n",
      "imageio                      2.33.1\n",
      "ipykernel                    6.29.0\n",
      "ipython                      8.20.0\n",
      "isoduration                  20.11.0\n",
      "jedi                         0.19.1\n",
      "Jinja2                       3.1.3\n",
      "json5                        0.9.14\n",
      "jsonpointer                  2.4\n",
      "jsonschema                   4.21.0\n",
      "jsonschema-specifications    2023.12.1\n",
      "jupyter_client               8.6.0\n",
      "jupyter_core                 5.7.1\n",
      "jupyter-events               0.9.0\n",
      "jupyter-lsp                  2.2.2\n",
      "jupyter_server               2.12.5\n",
      "jupyter_server_terminals     0.5.1\n",
      "jupyterlab                   4.0.10\n",
      "jupyterlab_pygments          0.3.0\n",
      "jupyterlab_server            2.25.2\n",
      "keras                        2.15.0\n",
      "kiwisolver                   1.4.5\n",
      "libclang                     16.0.6\n",
      "Markdown                     3.5.2\n",
      "MarkupSafe                   2.1.3\n",
      "matplotlib                   3.8.2\n",
      "matplotlib-inline            0.1.6\n",
      "mistune                      3.0.2\n",
      "ml-dtypes                    0.2.0\n",
      "nbclient                     0.9.0\n",
      "nbconvert                    7.14.2\n",
      "nbformat                     5.9.2\n",
      "nest-asyncio                 1.5.9\n",
      "notebook                     7.0.6\n",
      "notebook_shim                0.2.3\n",
      "numpy                        1.26.3\n",
      "oauthlib                     3.2.2\n",
      "opencv-python                4.9.0.80\n",
      "opt-einsum                   3.3.0\n",
      "overrides                    7.4.0\n",
      "packaging                    23.2\n",
      "pandocfilters                1.5.1\n",
      "parso                        0.8.3\n",
      "pexpect                      4.9.0\n",
      "pillow                       10.2.0\n",
      "pip                          23.2.1\n",
      "platformdirs                 4.1.0\n",
      "prometheus-client            0.19.0\n",
      "prompt-toolkit               3.0.43\n",
      "protobuf                     4.23.4\n",
      "psutil                       5.9.7\n",
      "ptyprocess                   0.7.0\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.5.1\n",
      "pyasn1-modules               0.3.0\n",
      "pycparser                    2.21\n",
      "Pygments                     2.17.2\n",
      "pyparsing                    3.1.1\n",
      "PySocks                      1.7.1\n",
      "python-dateutil              2.8.2\n",
      "python-json-logger           2.0.7\n",
      "PyYAML                       6.0.1\n",
      "pyzmq                        25.1.2\n",
      "referencing                  0.32.1\n",
      "requests                     2.31.0\n",
      "requests-oauthlib            1.3.1\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rpds-py                      0.17.1\n",
      "rsa                          4.9\n",
      "Send2Trash                   1.8.2\n",
      "setuptools                   65.5.0\n",
      "six                          1.16.0\n",
      "sniffio                      1.3.0\n",
      "soupsieve                    2.5\n",
      "stack-data                   0.6.3\n",
      "tensorboard                  2.15.1\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.15.0.post1\n",
      "tensorflow-estimator         2.15.0\n",
      "tensorflow-io-gcs-filesystem 0.35.0\n",
      "termcolor                    2.4.0\n",
      "terminado                    0.18.0\n",
      "tinycss2                     1.2.1\n",
      "tornado                      6.4\n",
      "tqdm                         4.66.1\n",
      "traitlets                    5.14.1\n",
      "types-python-dateutil        2.8.19.20240106\n",
      "typing_extensions            4.9.0\n",
      "uri-template                 1.3.0\n",
      "urllib3                      2.1.0\n",
      "wcwidth                      0.2.13\n",
      "webcolors                    1.13\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.7.0\n",
      "Werkzeug                     3.0.1\n",
      "wheel                        0.42.0\n",
      "wrapt                        1.14.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08413ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n"
     ]
    }
   ],
   "source": [
    "GOOGLE_DRIVE = False\n",
    "\n",
    "BASE_PATH = './'\n",
    "\n",
    "if GOOGLE_DRIVE is True:\n",
    "    BASE_PATH = '/content/drive/MyDrive/lipnet/' \n",
    "\n",
    "print(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f907ea-f669-46c7-adcf-7f257e663448",
   "metadata": {
    "id": "02f907ea-f669-46c7-adcf-7f257e663448",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python matplotlib imageio tensorflow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db068879-adf4-4151-8d7b-e505f798f77c",
   "metadata": {
    "cellView": "code",
    "id": "db068879-adf4-4151-8d7b-e505f798f77c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 18:28:18.098399: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-20 18:28:18.098466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-20 18:28:18.117950: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-20 18:28:18.167783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-20 18:28:18.939457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3db0b0-e559-4ad6-91fd-e7414b7d75e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e3db0b0-e559-4ad6-91fd-e7414b7d75e6",
    "outputId": "d6055b7b-afab-4a08-b261-53175770b301"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 18:28:20.021228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:20.106823: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:20.107030: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378d045a-3003-4f93-b7d2-a25a97774a68",
   "metadata": {
    "id": "378d045a-3003-4f93-b7d2-a25a97774a68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True) # GPU 메모리 사용 효율화\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
   "metadata": {
    "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
    "tags": []
   },
   "source": [
    "# 1. Build Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb99c90-e05a-437f-839d-6e772f8c1dd5",
   "metadata": {
    "id": "8fb99c90-e05a-437f-839d-6e772f8c1dd5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c019e4c6-2af3-4160-99ea-5c8cb009f1a7",
   "metadata": {
    "id": "c019e4c6-2af3-4160-99ea-5c8cb009f1a7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "# output = 'data.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0y4hkExqaI2o",
   "metadata": {
    "id": "0y4hkExqaI2o"
   },
   "outputs": [],
   "source": [
    "# def load_video(path: str) -> List[float]:\n",
    "#     cap = cv2.VideoCapture(path)\n",
    "#     frames = []\n",
    "#     for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "#         ret, frame = cap.read()\n",
    "#         frame = tf.constant(frame, dtype=tf.float32)  # 이미지를 텐서로 변환\n",
    "#         frame = tf.image.rgb_to_grayscale(frame)\n",
    "#         frames.append(frame[190:236, 80:220, :])\n",
    "#     cap.release()\n",
    "\n",
    "#     mean = tf.math.reduce_mean(frames)\n",
    "#     std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "#     return tf.cast((frames - mean), tf.float32) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
   "metadata": {
    "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]:\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    fn = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if fn != 75:\n",
    "      print(f'Wrong video! frame num: {fn}')\n",
    "\n",
    "    for _ in range(fn):\n",
    "        ret, frame = cap.read()\n",
    "        if frame is not None:\n",
    "          frame = tf.image.rgb_to_grayscale(frame)\n",
    "          frames.append(frame[190:236,80:220,:])\n",
    "        else:\n",
    "          print(\"load_video() path\" + path)\n",
    "    cap.release()\n",
    "\n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
   "metadata": {
    "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be04e972-d7a5-4a72-82d8-a6bdde1f3ce6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be04e972-d7a5-4a72-82d8-a6bdde1f3ce6",
    "outputId": "507c654d-6f61-46dc-fcf5-f3c5b60c16a7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 18:28:29.575180: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:29.575330: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:29.575420: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:29.647293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:29.647412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:29.647635: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:29.647714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7608 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "559f7420-6802-45fa-9ca0-b1ff209b461c",
   "metadata": {
    "id": "559f7420-6802-45fa-9ca0-b1ff209b461c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# char_to_num.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "797ff78b-b48f-4e14-bb62-8cd0ebf9501a",
   "metadata": {
    "id": "797ff78b-b48f-4e14-bb62-8cd0ebf9501a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# char_to_num(['n','i','c','k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cd7f4f4-ae77-4509-a4f4-c723787ebad1",
   "metadata": {
    "id": "8cd7f4f4-ae77-4509-a4f4-c723787ebad1"
   },
   "outputs": [],
   "source": [
    "# num_to_char([14,  9,  3, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9491bab5-6a3c-4f79-879a-8f9fbe73ae2e",
   "metadata": {
    "editable": true,
    "id": "9491bab5-6a3c-4f79-879a-8f9fbe73ae2e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]:\n",
    "    # print(\"load_alignments() path: \" + path)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil':  #.align 파일에서 마지막 컬럼 (sil, bin, blue..) 만 사용된다. 데이터를 만들 때 고려하지 않아도 되는 듯.\n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    # print(tokens) # [' ', 'bin', ' ', 'blue', ' ', 'at', ' ', 'l', ' ', 'six', ' ', 'now']\n",
    "    tokens = tf.strings.unicode_split(tokens, input_encoding='UTF-8')\n",
    "    # print(tokens)\n",
    "    tokens = tf.reshape(tokens, (-1))\n",
    "    # print(tokens)\n",
    "    tokens = char_to_num(tokens)[1:]\n",
    "    # print(tokens)\n",
    "    return tokens # tf.Tensor([ 2  9 14 39  2 12 21  5 39  1 20 39 12 39 19  9 24 39 14 15 23], shape=(21,), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd01ca9f-77fb-4643-a2aa-47dd82c5d66b",
   "metadata": {
    "id": "dd01ca9f-77fb-4643-a2aa-47dd82c5d66b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    path = bytes.decode(path.numpy())\n",
    "    # print(\"load_data() path: \" + path)\n",
    "    folder_name = path.split('/')[-2]\n",
    "    # print(\"load_data() folder_name: \" + folder_name)\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    # file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data', '150_less_intersect', f'{folder_name}',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data','150_less_intersect', 'alignments',f'{folder_name}',f'{file_name}.align')\n",
    "    # print(f'video_path: {video_path}')\n",
    "    # print(f'alignment_path: {alignment_path}')\n",
    "    \n",
    "    video_path = BASE_PATH + video_path\n",
    "    alignment_path = BASE_PATH + alignment_path\n",
    "\n",
    "    # print(video_path)\n",
    "    frames = load_video(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0b9288-9dee-4262-a868-6e289c14cadc",
   "metadata": {
    "id": "dd01ca9f-77fb-4643-a2aa-47dd82c5d66b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_test_data(path: str):\n",
    "    path = bytes.decode(path.numpy())\n",
    "    # print(\"load_data() path: \" + path)\n",
    "    folder_name = path.split('/')[-2]\n",
    "    # print(\"load_data() folder_name: \" + folder_name)\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    # file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data', f'{folder_name}',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data', 'alignments',f'{folder_name}',f'{file_name}.align')\n",
    "    # print(f'video_path: {video_path}')\n",
    "    # print(f'alignment_path: {alignment_path}')\n",
    "    \n",
    "    video_path = BASE_PATH + video_path\n",
    "    alignment_path = BASE_PATH + alignment_path\n",
    "\n",
    "    # print(video_path)\n",
    "    frames = load_video(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cb7cc58-31ae-4904-a805-1177a82717d2",
   "metadata": {
    "id": "8cb7cc58-31ae-4904-a805-1177a82717d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_path = BASE_PATH + 'data/s1_/lrwl5s.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76aa964f-0c84-490d-897a-d00e3966e2c9",
   "metadata": {
    "id": "76aa964f-0c84-490d-897a-d00e3966e2c9"
   },
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('\\\\')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd6815f2-678d-4198-87a2-1156ab41c359",
   "metadata": {
    "id": "fd6815f2-678d-4198-87a2-1156ab41c359"
   },
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb602c71-8560-4f9e-b26b-08202febb937",
   "metadata": {
    "id": "eb602c71-8560-4f9e-b26b-08202febb937",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frames, alignments = load_data(tf.convert_to_tensor(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "OsD7wS21b3VC",
   "metadata": {
    "id": "OsD7wS21b3VC"
   },
   "outputs": [],
   "source": [
    "# frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "LoQ1pUNEb7XR",
   "metadata": {
    "id": "LoQ1pUNEb7XR"
   },
   "outputs": [],
   "source": [
    "# alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfe004dd-8291-45c7-bbf1-b850990da564",
   "metadata": {
    "id": "bfe004dd-8291-45c7-bbf1-b850990da564"
   },
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e3184a1-6b02-4b4f-84a8-a0a65f951ea2",
   "metadata": {
    "id": "0e3184a1-6b02-4b4f-84a8-a0a65f951ea2"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(frames[4]) # frames of video (0 ~ 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7ec0833-d54b-4073-84cf-92d011c60ec1",
   "metadata": {
    "id": "d7ec0833-d54b-4073-84cf-92d011c60ec1"
   },
   "outputs": [],
   "source": [
    "# alignments #[' ', 'bin', ' ', 'blue', ' ', 'at', ' ', 'l', ' ', 'six', ' ', 'now']를 char_to_num을 이용해 숫자로 변환 한 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "255302a9-8a03-4164-a892-e48077b6aa9e",
   "metadata": {
    "id": "255302a9-8a03-4164-a892-e48077b6aa9e"
   },
   "outputs": [],
   "source": [
    "# alignments.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3823e59d-0919-4fba-b9d2-966ba7f59524",
   "metadata": {
    "id": "3823e59d-0919-4fba-b9d2-966ba7f59524"
   },
   "outputs": [],
   "source": [
    "# num_to_char(alignments.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eefdf11-8a49-4617-a73a-3765a03d352f",
   "metadata": {
    "id": "4eefdf11-8a49-4617-a73a-3765a03d352f"
   },
   "outputs": [],
   "source": [
    "# num_to_char(alignments.numpy()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bd43f1d-f263-475f-ba38-7683909da32b",
   "metadata": {
    "id": "6bd43f1d-f263-475f-ba38-7683909da32b"
   },
   "outputs": [],
   "source": [
    "# [bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe1ad370-b287-4b46-85a2-7c45b0bd9b10",
   "metadata": {
    "id": "fe1ad370-b287-4b46-85a2-7c45b0bd9b10"
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
   "metadata": {
    "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
   "metadata": {
    "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
    "tags": []
   },
   "source": [
    "# 2. Create Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bd1a6431-c19d-4315-b27e-95a40e644507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 하위 폴더를 돌며 '._' 로 시작하는 파일 지우기\n",
    "# import os\n",
    "\n",
    "# def remove_dotunderscore_files(root_folder):\n",
    "#     for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "#         for filename in filenames:\n",
    "#             if filename.startswith('._'):\n",
    "#                 file_path = os.path.join(foldername, filename)\n",
    "#                 os.remove(file_path)\n",
    "#                 print(f'Removed: {file_path}')\n",
    "\n",
    "# # 사용 예시\n",
    "# root_directory = './data/150_less_intersect'\n",
    "# remove_dotunderscore_files(root_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7686355d-45aa-4c85-ad9c-053e6a9b4d81",
   "metadata": {
    "id": "7686355d-45aa-4c85-ad9c-053e6a9b4d81",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "Yufekosh-Z9F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yufekosh-Z9F",
    "outputId": "c28a0366-68c5-4fa5-c8e2-e89a13a28df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1495\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 기본 디렉토리 경로\n",
    "base_dir = './data/150_less_intersect/'\n",
    "\n",
    "# 서브 디렉토리 목록 (s1부터 s10까지)\n",
    "# s8의 데이터는 문제가 많아서 제외\n",
    "sub_directories = [\n",
    "    # 's2_'\n",
    "    # 's1', 's2',\n",
    "    's1', 's2', 's3', 's4', 's5', 's6', 's7', 's9', 's10', 's11',\n",
    "    # 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20',\n",
    "    # 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's30',\n",
    "    # 's31', 's32', 's33', 's34'\n",
    "    ]\n",
    "\n",
    "# 모든 데이터셋을 담을 변수\n",
    "all_data = tf.data.Dataset.list_files([os.path.join(base_dir, sub_dir, '*.mpg') for sub_dir in sub_directories])\n",
    "# all_data = all_data.repeat(100) # 데이터 셋을 epoch 만큼 반복 시켜 늘림\n",
    "print(len(all_data))\n",
    "\n",
    "# 데이터를 메모리에 미리 로드\n",
    "# all_data = all_data.cache()\n",
    "\n",
    "\n",
    "# 데이터셋 확인\n",
    "# for file_path in all_data:\n",
    "    # print(file_path.numpy().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3d9c5e9-8345-411e-acb0-074a7694e154",
   "metadata": {
    "id": "d3d9c5e9-8345-411e-acb0-074a7694e154",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = all_data\n",
    "data_len = len(data)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "data = data.shuffle(int(data_len / 10), reshuffle_each_iteration=False) # shuffle for 10 %\n",
    "data = data.map(mappable_function) # load_data -> load_video/load_align 를 거쳐 입모양 부분만 뽑아낸 데이터들이 된다\n",
    "data = data.padded_batch(batch_size, padded_shapes=([75,None,None,None],[40])) # batch_size 개씩 묶어 배치를 구성. 전체 데이터의 수가 1000 / 2 = 500 이 된다. [40]: .align파일의 마지막 열에 있는 단어와 철자들의 합은 40이하이면 되고 모자란 경우 0으로 패딩된다\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Added for split\n",
    "train_num = int(data_len / batch_size * 0.8)\n",
    "train = data.take(train_num)\n",
    "test = data.skip(train_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "63443e18-1b24-499c-8efb-050d7d3f0269",
   "metadata": {
    "id": "63443e18-1b24-499c-8efb-050d7d3f0269",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frames, alignments = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "p2ROUZyOg3JA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2ROUZyOg3JA",
    "outputId": "b0616512-47a9-4d4d-8ec4-1fbdb44b7497"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "kk_1KR9lg5vF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kk_1KR9lg5vF",
    "outputId": "b32b39a0-1bce-4b94-b0ab-0fb4390960d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bea067a3-5bf2-4328-a604-e9a2f951a66f",
   "metadata": {
    "id": "bea067a3-5bf2-4328-a604-e9a2f951a66f"
   },
   "outputs": [],
   "source": [
    "# print(\"Frames Shape:\", frames.shape)\n",
    "# print(\"Alignments Shape:\", alignments.shape)\n",
    "\n",
    "# 만약 값이 너무 크다면, 첫 번째 프레임과 정렬 정보의 일부를 출력해 보세요.\n",
    "# print(\"First Frame:\", frames[0])\n",
    "# print(\"First Alignment:\", alignments[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "07a9aa19-5c53-493c-aa79-c33a366e5220",
   "metadata": {
    "id": "07a9aa19-5c53-493c-aa79-c33a366e5220"
   },
   "outputs": [],
   "source": [
    "# len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e58c6bba-347c-4a91-8086-f90c60f56dc9",
   "metadata": {
    "id": "e58c6bba-347c-4a91-8086-f90c60f56dc9"
   },
   "outputs": [],
   "source": [
    "# len(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
   "metadata": {
    "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
   "metadata": {
    "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val = sample.next(); val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "acf5eb4f-a0da-4a9a-bf24-af13e9cc2fbe",
   "metadata": {
    "id": "acf5eb4f-a0da-4a9a-bf24-af13e9cc2fbe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imageio.mimsave('./animation.gif', val[0][0], fps=10)\n",
    "# imageio.mimsave('./animation.gif', val[0][0].squeeze(), fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c33a87a2-d5e0-4ec9-b174-73ebf41bf03a",
   "metadata": {
    "id": "c33a87a2-d5e0-4ec9-b174-73ebf41bf03a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0:videos(1:alignments), 0: 1st video out of the batch(0~1),  0: return the first frame in the video(0~74)\n",
    "# plt.imshow(val[0][0][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46175921-6721-4138-b511-b50573a05567",
   "metadata": {
    "id": "46175921-6721-4138-b511-b50573a05567",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])\n",
    "# ([num_to_char(word) for word in val[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ce8a026-d112-4470-a848-89e626a76772",
   "metadata": {
    "id": "7ce8a026-d112-4470-a848-89e626a76772",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ([(word) for word in val[1][0]]) #마지막에 0의 연속이 들어간 것은 패딩의 효과 인듯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47733c-83bc-465c-b118-b198b492ad37",
   "metadata": {
    "id": "0f47733c-83bc-465c-b118-b198b492ad37",
    "tags": []
   },
   "source": [
    "# 3. Design the Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
   "metadata": {
    "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam #`tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`\n",
    "# from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3f753ed2-70b9-4236-8c1c-08ca065dc8bf",
   "metadata": {
    "id": "3f753ed2-70b9-4236-8c1c-08ca065dc8bf"
   },
   "outputs": [],
   "source": [
    "# data.as_numpy_iterator().next()[0][0].shape #[0: video][0: 배치 중 1번째]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f9171056-a352-491a-9ed9-92b28ced268e",
   "metadata": {
    "id": "f9171056-a352-491a-9ed9-92b28ced268e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "78851825-2bcd-42a9-b7f2-28bb5a6bf43a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78851825-2bcd-42a9-b7f2-28bb5a6bf43a",
    "outputId": "0715cb32-fe41-45b7-d2e3-846d0cdfd657",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_3 (Conv3D)           (None, 75, 46, 140, 128   3584      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 75, 46, 140, 128   0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPoolin  (None, 75, 23, 70, 128)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 75, 23, 70, 256)   884992    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 75, 23, 70, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPoolin  (None, 75, 11, 35, 256)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 75, 11, 35, 75)    518475    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 75, 11, 35, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPoolin  (None, 75, 5, 17, 75)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 75, 6375)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 75, 256)           6660096   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 75, 256)           394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 75, 41)            10537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8471924 (32.32 MB)\n",
      "Trainable params: 8471924 (32.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f4b4798c-a65a-4c47-9e2a-3b09dc98d320",
   "metadata": {
    "id": "f4b4798c-a65a-4c47-9e2a-3b09dc98d320"
   },
   "outputs": [],
   "source": [
    "# 5*17*75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5c2eae0-c359-41a4-97a0-75c44dccb7d1",
   "metadata": {
    "id": "e5c2eae0-c359-41a4-97a0-75c44dccb7d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yhat = model.predict(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ffdc7319-0d69-4f7e-a6d4-ce72deb81c0b",
   "metadata": {
    "id": "ffdc7319-0d69-4f7e-a6d4-ce72deb81c0b"
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8d15c83-c18e-4812-a3e0-6d4b2eb3d302",
   "metadata": {
    "id": "a8d15c83-c18e-4812-a3e0-6d4b2eb3d302"
   },
   "outputs": [],
   "source": [
    "# tf.argmax(yhat[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ed47531-8317-4255-9a12-b757642258e6",
   "metadata": {
    "id": "6ed47531-8317-4255-9a12-b757642258e6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in yhat[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c37b9b9-5298-4038-9c33-5031d1b457f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c37b9b9-5298-4038-9c33-5031d1b457f0",
    "outputId": "ae515f10-318b-4e0a-e563-a4cf3a865a3e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 75, 46, 140, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98b316a4-5322-4782-8e36-4b3c1a696d85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98b316a4-5322-4782-8e36-4b3c1a696d85",
    "outputId": "e8a55eac-50da-405d-9234-d60e29af6e54",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 75, 41)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
   "metadata": {
    "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
    "tags": []
   },
   "source": [
    "# 4. Setup Training Options and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
   "metadata": {
    "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c564d5c9-db54-4e88-b311-9aeab7fb3e69",
   "metadata": {
    "id": "c564d5c9-db54-4e88-b311-9aeab7fb3e69",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a26dc3fc-a19c-4378-bd8c-e2b597a1d15c",
   "metadata": {
    "id": "a26dc3fc-a19c-4378-bd8c-e2b597a1d15c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, dataset_) -> None:\n",
    "        self.dataset = dataset_\n",
    "        print(self.dataset)\n",
    "        self.iterator = self.dataset.as_numpy_iterator()\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        try:\n",
    "            data = self.iterator.next()\n",
    "        except StopIteration:\n",
    "            self.iterator = self.dataset.as_numpy_iterator()\n",
    "            data = self.iterator.next()\n",
    "\n",
    "        yhat = self.model.predict(data[0])\n",
    "        print(\"yhat------------\")\n",
    "        print(yhat.shape)\n",
    "        print(yhat[0][0])\n",
    "        print(yhat.shape[0])\n",
    "        print(yhat)\n",
    "\n",
    "        batch_size_ = yhat.shape[0]\n",
    "        print(batch_size_)\n",
    "        print(f'len yhat: {len(yhat)}')\n",
    "\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75] * batch_size_, greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):\n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
    "outputId": "5bfc3bb5-d4e4-4a94-87f8-47c1e924bc6d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_SkipDataset element_spec=(TensorSpec(shape=(None, 75, None, None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 40), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)\n",
    "checkpoint_callback = ModelCheckpoint(os.path.join(BASE_PATH + 'models','checkpoint'), monitor='loss', save_weights_only=True)\n",
    "schedule_callback = LearningRateScheduler(scheduler)\n",
    "example_callback = ProduceExample(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "PLoaICYFl_KP",
   "metadata": {
    "id": "PLoaICYFl_KP"
   },
   "outputs": [],
   "source": [
    "# spe = int(data_len / batch_size)\n",
    "# print(\"steps_per_epoch: \" + str(spe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "39e0ece1-1c23-4b61-9c8e-10318f032fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이스백 필터링 비활성화\n",
    "tf.debugging.disable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fe65e229-c79b-4b12-a7f5-7361ebf6d8d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5a625d61-76ec-494a-a3a0-551807c49373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn version:8901\n",
      "cuda version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# print(\"TensorFlow version:\", tf.__version__)\n",
    "# print(\"CUDA version:\", tf.test.is_built_with_cuda())\n",
    "# # print(\"cuDNN version:\", tf.test.is_built_with_cudnn())\n",
    "# print(\"cuDNN version:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "import torch\n",
    "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))\n",
    "print(\"cuda version: {}\".format(torch.version.cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Iap7RVFEL-16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iap7RVFEL-16",
    "outputId": "ad12c36d-4f85-429a-c9cc-fffcb892b37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 458/1196 [==========>...................] - ETA: 2:00 - loss: 87.3003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f3df802d740] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f3df802d740] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099/1196 [==========================>...] - ETA: 15s - loss: 77.8372"
     ]
    }
   ],
   "source": [
    "model.fit(train, validation_data=test, epochs=50, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccaa452-2c3b-4fee-bcc2-2223b4d21506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이스백 필터링 다시 활성화\n",
    "tf.debugging.enable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
   "metadata": {
    "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
    "tags": []
   },
   "source": [
    "# 5. Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
   "metadata": {
    "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "# output = 'checkpoints.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('checkpoints.zip', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
   "metadata": {
    "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f2cd0435550>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(BASE_PATH + 'models/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f8d689f-b7bb-443c-9b88-e40c1d800828",
   "metadata": {
    "id": "7f8d689f-b7bb-443c-9b88-e40c1d800828",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
   "metadata": {
    "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = test_data.next() # 첫 실행시 오래 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
   "metadata": {
    "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
   "metadata": {
    "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'lay blue at q zero please'>]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
   "metadata": {
    "editable": true,
    "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75] * batch_size, greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
   "metadata": {
    "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'lay blue at q zero please'>]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431",
   "metadata": {
    "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431"
   },
   "source": [
    "# 6. Test on a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9358ea64-014f-4ef1-b30f-1f6a1e28f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤하게 선택된 .mpg 파일 경로: ./data/s30/bgbe8a.mpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def get_random_mpg_path(root_folder):\n",
    "    mpg_files = []\n",
    "    \n",
    "    # root_folder와 그 하위 폴더에서 .mpg 파일 찾기\n",
    "    for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.mpg'):\n",
    "                mpg_files.append(os.path.join(foldername, filename))\n",
    "    \n",
    "    # .mpg 파일이 없으면 None 반환\n",
    "    if not mpg_files:\n",
    "        return None\n",
    "    \n",
    "    # 랜덤하게 선택된 .mpg 파일 경로 반환\n",
    "    return random.choice(mpg_files)\n",
    "\n",
    "# 사용 예시\n",
    "root_folder = BASE_PATH + 'data/'\n",
    "random_mpg_path = get_random_mpg_path(root_folder)\n",
    "\n",
    "if random_mpg_path:\n",
    "    print(f'랜덤하게 선택된 .mpg 파일 경로: {random_mpg_path}')\n",
    "else:\n",
    "    print('폴더 안에 .mpg 파일이 없습니다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1cfca9b6-ebab-45e7-9574-11b5e5839ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/s34/pbil2s.mpg\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'place blue in l two soon'>]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. load random data (from s1 ~ s34, 훈련 데이터에 포함된 것도 있음. s12 부터는 훈련 데이터에 포함되지 않음.)\n",
    "test_path = get_random_mpg_path(root_folder)\n",
    "print(test_path)\n",
    "sample = load_test_data(tf.convert_to_tensor(test_path))\n",
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e91ba72d-5c01-45ea-892f-50ed5b79f39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'lay gree it u eive sleasn'>]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. predict\n",
    "yhat = model.predict(tf.expand_dims(sample[0], axis=0))\n",
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()\n",
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed636ef3-39d9-47ec-a3c6-7b21b035f3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
