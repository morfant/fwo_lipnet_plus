{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
   "metadata": {
    "editable": true,
    "id": "a3573a47-3689-4668-b62f-5c8451b2b4e9",
    "tags": []
   },
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ni0KA3RDVbC4",
   "metadata": {
    "id": "ni0KA3RDVbC4"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddfbccbe-41ae-4c23-98b1-a13868e2b499",
   "metadata": {
    "id": "ddfbccbe-41ae-4c23-98b1-a13868e2b499",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------------\n",
      "absl-py                      2.1.0\n",
      "anyio                        4.2.0\n",
      "argon2-cffi                  23.1.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.3.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "async-lru                    2.0.4\n",
      "attrs                        23.2.0\n",
      "Babel                        2.14.0\n",
      "beautifulsoup4               4.12.3\n",
      "bleach                       6.1.0\n",
      "cachetools                   5.3.2\n",
      "certifi                      2023.11.17\n",
      "cffi                         1.16.0\n",
      "charset-normalizer           3.3.2\n",
      "comm                         0.2.1\n",
      "contourpy                    1.2.0\n",
      "cycler                       0.12.1\n",
      "debugpy                      1.8.0\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "executing                    2.0.1\n",
      "fastjsonschema               2.19.1\n",
      "filelock                     3.13.1\n",
      "flatbuffers                  23.5.26\n",
      "fonttools                    4.47.2\n",
      "fqdn                         1.5.1\n",
      "gast                         0.5.4\n",
      "gdown                        4.7.3\n",
      "google-auth                  2.26.2\n",
      "google-auth-oauthlib         1.2.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.60.0\n",
      "h5py                         3.10.0\n",
      "idna                         3.6\n",
      "imageio                      2.33.1\n",
      "ipykernel                    6.29.0\n",
      "ipython                      8.20.0\n",
      "isoduration                  20.11.0\n",
      "jedi                         0.19.1\n",
      "Jinja2                       3.1.3\n",
      "json5                        0.9.14\n",
      "jsonpointer                  2.4\n",
      "jsonschema                   4.21.0\n",
      "jsonschema-specifications    2023.12.1\n",
      "jupyter_client               8.6.0\n",
      "jupyter_core                 5.7.1\n",
      "jupyter-events               0.9.0\n",
      "jupyter-lsp                  2.2.2\n",
      "jupyter_server               2.12.5\n",
      "jupyter_server_terminals     0.5.1\n",
      "jupyterlab                   4.0.10\n",
      "jupyterlab_pygments          0.3.0\n",
      "jupyterlab_server            2.25.2\n",
      "keras                        2.15.0\n",
      "kiwisolver                   1.4.5\n",
      "libclang                     16.0.6\n",
      "Markdown                     3.5.2\n",
      "MarkupSafe                   2.1.3\n",
      "matplotlib                   3.8.2\n",
      "matplotlib-inline            0.1.6\n",
      "mistune                      3.0.2\n",
      "ml-dtypes                    0.2.0\n",
      "nbclient                     0.9.0\n",
      "nbconvert                    7.14.2\n",
      "nbformat                     5.9.2\n",
      "nest-asyncio                 1.5.9\n",
      "notebook                     7.0.6\n",
      "notebook_shim                0.2.3\n",
      "numpy                        1.26.3\n",
      "oauthlib                     3.2.2\n",
      "opencv-python                4.9.0.80\n",
      "opt-einsum                   3.3.0\n",
      "overrides                    7.4.0\n",
      "packaging                    23.2\n",
      "pandocfilters                1.5.1\n",
      "parso                        0.8.3\n",
      "pexpect                      4.9.0\n",
      "pillow                       10.2.0\n",
      "pip                          23.2.1\n",
      "platformdirs                 4.1.0\n",
      "prometheus-client            0.19.0\n",
      "prompt-toolkit               3.0.43\n",
      "protobuf                     4.23.4\n",
      "psutil                       5.9.7\n",
      "ptyprocess                   0.7.0\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.5.1\n",
      "pyasn1-modules               0.3.0\n",
      "pycparser                    2.21\n",
      "Pygments                     2.17.2\n",
      "pyparsing                    3.1.1\n",
      "PySocks                      1.7.1\n",
      "python-dateutil              2.8.2\n",
      "python-json-logger           2.0.7\n",
      "PyYAML                       6.0.1\n",
      "pyzmq                        25.1.2\n",
      "referencing                  0.32.1\n",
      "requests                     2.31.0\n",
      "requests-oauthlib            1.3.1\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rpds-py                      0.17.1\n",
      "rsa                          4.9\n",
      "Send2Trash                   1.8.2\n",
      "setuptools                   65.5.0\n",
      "six                          1.16.0\n",
      "sniffio                      1.3.0\n",
      "soupsieve                    2.5\n",
      "stack-data                   0.6.3\n",
      "tensorboard                  2.15.1\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.15.0.post1\n",
      "tensorflow-estimator         2.15.0\n",
      "tensorflow-io-gcs-filesystem 0.35.0\n",
      "termcolor                    2.4.0\n",
      "terminado                    0.18.0\n",
      "tinycss2                     1.2.1\n",
      "tornado                      6.4\n",
      "tqdm                         4.66.1\n",
      "traitlets                    5.14.1\n",
      "types-python-dateutil        2.8.19.20240106\n",
      "typing_extensions            4.9.0\n",
      "uri-template                 1.3.0\n",
      "urllib3                      2.1.0\n",
      "wcwidth                      0.2.13\n",
      "webcolors                    1.13\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.7.0\n",
      "Werkzeug                     3.0.1\n",
      "wheel                        0.42.0\n",
      "wrapt                        1.14.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08413ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n"
     ]
    }
   ],
   "source": [
    "GOOGLE_DRIVE = False\n",
    "\n",
    "BASE_PATH = './'\n",
    "\n",
    "if GOOGLE_DRIVE is True:\n",
    "    BASE_PATH = '/content/drive/MyDrive/lipnet/' \n",
    "\n",
    "print(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f907ea-f669-46c7-adcf-7f257e663448",
   "metadata": {
    "id": "02f907ea-f669-46c7-adcf-7f257e663448",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python matplotlib imageio tensorflow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db068879-adf4-4151-8d7b-e505f798f77c",
   "metadata": {
    "cellView": "code",
    "id": "db068879-adf4-4151-8d7b-e505f798f77c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3db0b0-e559-4ad6-91fd-e7414b7d75e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e3db0b0-e559-4ad6-91fd-e7414b7d75e6",
    "outputId": "d6055b7b-afab-4a08-b261-53175770b301"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 18:28:20.021228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:20.106823: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-20 18:28:20.107030: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378d045a-3003-4f93-b7d2-a25a97774a68",
   "metadata": {
    "id": "378d045a-3003-4f93-b7d2-a25a97774a68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True) # GPU 메모리 사용 효율화\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
   "metadata": {
    "id": "7a19e88e-c7b9-45c1-ae1e-f2109329c71b",
    "tags": []
   },
   "source": [
    "# 1. Build Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb99c90-e05a-437f-839d-6e772f8c1dd5",
   "metadata": {
    "id": "8fb99c90-e05a-437f-839d-6e772f8c1dd5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c019e4c6-2af3-4160-99ea-5c8cb009f1a7",
   "metadata": {
    "id": "c019e4c6-2af3-4160-99ea-5c8cb009f1a7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "# output = 'data.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0y4hkExqaI2o",
   "metadata": {
    "id": "0y4hkExqaI2o"
   },
   "outputs": [],
   "source": [
    "# def load_video(path: str) -> List[float]:\n",
    "#     cap = cv2.VideoCapture(path)\n",
    "#     frames = []\n",
    "#     for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "#         ret, frame = cap.read()\n",
    "#         frame = tf.constant(frame, dtype=tf.float32)  # 이미지를 텐서로 변환\n",
    "#         frame = tf.image.rgb_to_grayscale(frame)\n",
    "#         frames.append(frame[190:236, 80:220, :])\n",
    "#     cap.release()\n",
    "\n",
    "#     mean = tf.math.reduce_mean(frames)\n",
    "#     std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "#     return tf.cast((frames - mean), tf.float32) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4413ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cropped_frames(folder_path: str) -> List[float]:\n",
    "    frames = []\n",
    "\n",
    "    # print(f'load_cropped_frames(): {folder_path}')\n",
    "    # Get a list of image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png'))]\n",
    "    image_files.sort()  # Sort files to ensure the correct order\n",
    "\n",
    "    fn = len(image_files)\n",
    "\n",
    "    if fn != 75:\n",
    "        print(f'Wrong number of frames! Number of frames: {fn}')\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Construct the full path to the image file\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "\n",
    "        # Read the image using OpenCV\n",
    "        frame = cv2.imread(image_path)\n",
    "\n",
    "        if frame is not None:\n",
    "            # Convert to grayscale\n",
    "            frame = tf.image.rgb_to_grayscale(frame)\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    normalized_frames = tf.cast((frames - mean), tf.float32) / std\n",
    "\n",
    "    return normalized_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
   "metadata": {
    "id": "8548cc59-6dfc-4acc-abc3-3e65212db02e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def load_video(path:str) -> List[float]:\n",
    "\n",
    "#     cap = cv2.VideoCapture(path)\n",
    "#     frames = []\n",
    "#     fn = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#     if fn != 75:\n",
    "#       print(f'Wrong video! frame num: {fn}')\n",
    "\n",
    "#     for _ in range(fn):\n",
    "#         ret, frame = cap.read()\n",
    "#         if frame is not None:\n",
    "#           frame = tf.image.rgb_to_grayscale(frame)\n",
    "#           frames.append(frame[190:236,80:220,:])\n",
    "#         else:\n",
    "#           print(\"load_video() path\" + path)\n",
    "#     cap.release()\n",
    "\n",
    "#     mean = tf.math.reduce_mean(frames)\n",
    "#     std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "#     return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
   "metadata": {
    "id": "ec735e0b-ec98-4eb0-8f49-c35527d6670a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be04e972-d7a5-4a72-82d8-a6bdde1f3ce6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be04e972-d7a5-4a72-82d8-a6bdde1f3ce6",
    "outputId": "507c654d-6f61-46dc-fcf5-f3c5b60c16a7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
     ]
    }
   ],
   "source": [
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "559f7420-6802-45fa-9ca0-b1ff209b461c",
   "metadata": {
    "id": "559f7420-6802-45fa-9ca0-b1ff209b461c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# char_to_num.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "797ff78b-b48f-4e14-bb62-8cd0ebf9501a",
   "metadata": {
    "id": "797ff78b-b48f-4e14-bb62-8cd0ebf9501a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# char_to_num(['n','i','c','k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cd7f4f4-ae77-4509-a4f4-c723787ebad1",
   "metadata": {
    "id": "8cd7f4f4-ae77-4509-a4f4-c723787ebad1"
   },
   "outputs": [],
   "source": [
    "# num_to_char([14,  9,  3, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9491bab5-6a3c-4f79-879a-8f9fbe73ae2e",
   "metadata": {
    "editable": true,
    "id": "9491bab5-6a3c-4f79-879a-8f9fbe73ae2e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]:\n",
    "    # print(\"load_alignments() path: \" + path)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil':  #.align 파일에서 마지막 컬럼 (sil, bin, blue..) 만 사용된다. 데이터를 만들 때 고려하지 않아도 되는 듯.\n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    # print(tokens) # [' ', 'bin', ' ', 'blue', ' ', 'at', ' ', 'l', ' ', 'six', ' ', 'now']\n",
    "    tokens = tf.strings.unicode_split(tokens, input_encoding='UTF-8')\n",
    "    # print(tokens)\n",
    "    tokens = tf.reshape(tokens, (-1))\n",
    "    # print(tokens)\n",
    "    tokens = char_to_num(tokens)[1:]\n",
    "    # print(tokens)\n",
    "    return tokens # tf.Tensor([ 2  9 14 39  2 12 21  5 39  1 20 39 12 39 19  9 24 39 14 15 23], shape=(21,), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd01ca9f-77fb-4643-a2aa-47dd82c5d66b",
   "metadata": {
    "id": "dd01ca9f-77fb-4643-a2aa-47dd82c5d66b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    subpath = '111'\n",
    "    path = bytes.decode(path.numpy())\n",
    "    # print(\"load_data() path: \" + path)\n",
    "    folder_name = path.split('/')[-2]\n",
    "    # print(\"load_data() folder_name: \" + folder_name)\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    # file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data', subpath, f'{folder_name}', 'cropped', f'{file_name}')\n",
    "    alignment_path = os.path.join('data', subpath, 'alignments', f'{folder_name}',f'{file_name}.align')\n",
    "    # print(f'video_path: {video_path}')\n",
    "    # print(f'alignment_path: {alignment_path}')\n",
    "    \n",
    "    video_path = BASE_PATH + video_path\n",
    "    alignment_path = BASE_PATH + alignment_path\n",
    "\n",
    "    # print(video_path)\n",
    "    # frames = load_video(video_path)\n",
    "    frames = load_cropped_frames(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c0b9288-9dee-4262-a868-6e289c14cadc",
   "metadata": {
    "id": "dd01ca9f-77fb-4643-a2aa-47dd82c5d66b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_test_data(path: str):\n",
    "    path = bytes.decode(path.numpy())\n",
    "    # print(\"load_data() path: \" + path)\n",
    "    folder_name = path.split('/')[-2]\n",
    "    # print(\"load_data() folder_name: \" + folder_name)\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    # file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data', f'{folder_name}',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data', 'alignments',f'{folder_name}',f'{file_name}.align')\n",
    "    # print(f'video_path: {video_path}')\n",
    "    # print(f'alignment_path: {alignment_path}')\n",
    "    \n",
    "    video_path = BASE_PATH + video_path\n",
    "    alignment_path = BASE_PATH + alignment_path\n",
    "\n",
    "    # print(video_path)\n",
    "    frames = load_video(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cb7cc58-31ae-4904-a805-1177a82717d2",
   "metadata": {
    "id": "8cb7cc58-31ae-4904-a805-1177a82717d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_path = BASE_PATH + 'data/111/s1/bbaf4p.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76aa964f-0c84-490d-897a-d00e3966e2c9",
   "metadata": {
    "id": "76aa964f-0c84-490d-897a-d00e3966e2c9"
   },
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('\\\\')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd6815f2-678d-4198-87a2-1156ab41c359",
   "metadata": {
    "id": "fd6815f2-678d-4198-87a2-1156ab41c359"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bbaf4p'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb602c71-8560-4f9e-b26b-08202febb937",
   "metadata": {
    "id": "eb602c71-8560-4f9e-b26b-08202febb937",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames, alignments = load_data(tf.convert_to_tensor(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "OsD7wS21b3VC",
   "metadata": {
    "id": "OsD7wS21b3VC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(75, 50, 100, 1), dtype=float32, numpy=\n",
       "array([[[[1.9879462 ],\n",
       "         [1.9084283 ],\n",
       "         [1.8289105 ],\n",
       "         ...,\n",
       "         [0.71566063],\n",
       "         [0.75541955],\n",
       "         [0.8746963 ]],\n",
       "\n",
       "        [[1.9481872 ],\n",
       "         [1.8686694 ],\n",
       "         [1.7891515 ],\n",
       "         ...,\n",
       "         [0.8349374 ],\n",
       "         [0.8349374 ],\n",
       "         [0.91445524]],\n",
       "\n",
       "        [[1.9084283 ],\n",
       "         [1.8686694 ],\n",
       "         [1.7891515 ],\n",
       "         ...,\n",
       "         [0.91445524],\n",
       "         [0.8746963 ],\n",
       "         [0.8746963 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.59638387],\n",
       "         [1.7096337 ],\n",
       "         [1.6698748 ],\n",
       "         ...,\n",
       "         [0.8746963 ],\n",
       "         [0.8746963 ],\n",
       "         [0.71566063]],\n",
       "\n",
       "        [[0.39758924],\n",
       "         [1.550598  ],\n",
       "         [1.6698748 ],\n",
       "         ...,\n",
       "         [0.6759017 ],\n",
       "         [0.516866  ],\n",
       "         [0.1590357 ]],\n",
       "\n",
       "        [[0.03975892],\n",
       "         [1.4710802 ],\n",
       "         [1.7096337 ],\n",
       "         ...,\n",
       "         [0.6361428 ],\n",
       "         [0.3180714 ],\n",
       "         [9.939731  ]]],\n",
       "\n",
       "\n",
       "       [[[1.9879462 ],\n",
       "         [1.9084283 ],\n",
       "         [1.8289105 ],\n",
       "         ...,\n",
       "         [0.6759017 ],\n",
       "         [0.71566063],\n",
       "         [0.8349374 ]],\n",
       "\n",
       "        [[1.9481872 ],\n",
       "         [1.9084283 ],\n",
       "         [1.7891515 ],\n",
       "         ...,\n",
       "         [0.7951785 ],\n",
       "         [0.8349374 ],\n",
       "         [0.75541955]],\n",
       "\n",
       "        [[1.9481872 ],\n",
       "         [1.8686694 ],\n",
       "         [1.7493926 ],\n",
       "         ...,\n",
       "         [0.8349374 ],\n",
       "         [0.8746963 ],\n",
       "         [0.75541955]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8349374 ],\n",
       "         [1.9084283 ],\n",
       "         [1.7493926 ],\n",
       "         ...,\n",
       "         [0.8349374 ],\n",
       "         [0.95421416],\n",
       "         [0.75541955]],\n",
       "\n",
       "        [[0.55662495],\n",
       "         [1.7891515 ],\n",
       "         [1.7891515 ],\n",
       "         ...,\n",
       "         [0.6759017 ],\n",
       "         [0.516866  ],\n",
       "         [0.11927677]],\n",
       "\n",
       "        [[0.11927677],\n",
       "         [1.6301159 ],\n",
       "         [1.7493926 ],\n",
       "         ...,\n",
       "         [0.71566063],\n",
       "         [0.1590357 ],\n",
       "         [9.899972  ]]],\n",
       "\n",
       "\n",
       "       [[[1.9084283 ],\n",
       "         [1.9084283 ],\n",
       "         [1.8289105 ],\n",
       "         ...,\n",
       "         [0.516866  ],\n",
       "         [0.59638387],\n",
       "         [0.7951785 ]],\n",
       "\n",
       "        [[1.9084283 ],\n",
       "         [1.8686694 ],\n",
       "         [1.7891515 ],\n",
       "         ...,\n",
       "         [0.6759017 ],\n",
       "         [0.75541955],\n",
       "         [0.8746963 ]],\n",
       "\n",
       "        [[1.9084283 ],\n",
       "         [1.8686694 ],\n",
       "         [1.7891515 ],\n",
       "         ...,\n",
       "         [0.7951785 ],\n",
       "         [0.8349374 ],\n",
       "         [0.8349374 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.91445524],\n",
       "         [1.9481872 ],\n",
       "         [1.7493926 ],\n",
       "         ...,\n",
       "         [0.91445524],\n",
       "         [1.1530088 ],\n",
       "         [1.073491  ]],\n",
       "\n",
       "        [[0.75541955],\n",
       "         [1.8686694 ],\n",
       "         [1.7891515 ],\n",
       "         ...,\n",
       "         [0.75541955],\n",
       "         [0.91445524],\n",
       "         [0.6759017 ]],\n",
       "\n",
       "        [[0.516866  ],\n",
       "         [1.7891515 ],\n",
       "         [1.7891515 ],\n",
       "         ...,\n",
       "         [0.6759017 ],\n",
       "         [0.47710708],\n",
       "         [0.07951785]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[2.067464  ],\n",
       "         [1.9879462 ],\n",
       "         [1.9084283 ],\n",
       "         ...,\n",
       "         [0.55662495],\n",
       "         [0.59638387],\n",
       "         [0.6759017 ]],\n",
       "\n",
       "        [[2.067464  ],\n",
       "         [1.9481872 ],\n",
       "         [1.9084283 ],\n",
       "         ...,\n",
       "         [0.75541955],\n",
       "         [0.6759017 ],\n",
       "         [0.75541955]],\n",
       "\n",
       "        [[1.9879462 ],\n",
       "         [1.9481872 ],\n",
       "         [1.8686694 ],\n",
       "         ...,\n",
       "         [0.8746963 ],\n",
       "         [0.7951785 ],\n",
       "         [0.8746963 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.661418  ],\n",
       "         [1.6301159 ],\n",
       "         [1.9084283 ],\n",
       "         ...,\n",
       "         [1.073491  ],\n",
       "         [1.2325267 ],\n",
       "         [1.2722856 ]],\n",
       "\n",
       "        [[9.701178  ],\n",
       "         [1.550598  ],\n",
       "         [1.8686694 ],\n",
       "         ...,\n",
       "         [0.91445524],\n",
       "         [0.9939731 ],\n",
       "         [0.95421416]],\n",
       "\n",
       "        [[9.621659  ],\n",
       "         [1.3518034 ],\n",
       "         [1.8686694 ],\n",
       "         ...,\n",
       "         [0.75541955],\n",
       "         [0.6759017 ],\n",
       "         [0.55662495]]],\n",
       "\n",
       "\n",
       "       [[[2.107223  ],\n",
       "         [1.9879462 ],\n",
       "         [1.9481872 ],\n",
       "         ...,\n",
       "         [0.55662495],\n",
       "         [0.55662495],\n",
       "         [0.75541955]],\n",
       "\n",
       "        [[2.107223  ],\n",
       "         [1.9879462 ],\n",
       "         [1.9084283 ],\n",
       "         ...,\n",
       "         [0.71566063],\n",
       "         [0.6759017 ],\n",
       "         [0.7951785 ]],\n",
       "\n",
       "        [[2.067464  ],\n",
       "         [1.9879462 ],\n",
       "         [1.8686694 ],\n",
       "         ...,\n",
       "         [0.8746963 ],\n",
       "         [0.8349374 ],\n",
       "         [0.8746963 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.820454  ],\n",
       "         [1.7096337 ],\n",
       "         [1.8289105 ],\n",
       "         ...,\n",
       "         [1.073491  ],\n",
       "         [1.1530088 ],\n",
       "         [1.3120445 ]],\n",
       "\n",
       "        [[9.820454  ],\n",
       "         [1.6301159 ],\n",
       "         [1.8686694 ],\n",
       "         ...,\n",
       "         [0.91445524],\n",
       "         [0.95421416],\n",
       "         [0.95421416]],\n",
       "\n",
       "        [[9.740936  ],\n",
       "         [1.4710802 ],\n",
       "         [1.8686694 ],\n",
       "         ...,\n",
       "         [0.75541955],\n",
       "         [0.71566063],\n",
       "         [0.43734816]]],\n",
       "\n",
       "\n",
       "       [[[2.067464  ],\n",
       "         [1.9879462 ],\n",
       "         [1.9481872 ],\n",
       "         ...,\n",
       "         [0.47710708],\n",
       "         [0.516866  ],\n",
       "         [0.75541955]],\n",
       "\n",
       "        [[2.067464  ],\n",
       "         [1.9879462 ],\n",
       "         [1.9084283 ],\n",
       "         ...,\n",
       "         [0.6361428 ],\n",
       "         [0.6361428 ],\n",
       "         [0.75541955]],\n",
       "\n",
       "        [[2.067464  ],\n",
       "         [1.9879462 ],\n",
       "         [1.8686694 ],\n",
       "         ...,\n",
       "         [0.7951785 ],\n",
       "         [0.75541955],\n",
       "         [0.8349374 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.939731  ],\n",
       "         [1.7493926 ],\n",
       "         [1.8686694 ],\n",
       "         ...,\n",
       "         [1.1132499 ],\n",
       "         [1.2722856 ],\n",
       "         [1.3518034 ]],\n",
       "\n",
       "        [[9.899972  ],\n",
       "         [1.6698748 ],\n",
       "         [1.8686694 ],\n",
       "         ...,\n",
       "         [0.91445524],\n",
       "         [1.073491  ],\n",
       "         [1.033732  ]],\n",
       "\n",
       "        [[9.899972  ],\n",
       "         [1.550598  ],\n",
       "         [1.9084283 ],\n",
       "         ...,\n",
       "         [0.71566063],\n",
       "         [0.7951785 ],\n",
       "         [0.516866  ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "LoQ1pUNEb7XR",
   "metadata": {
    "id": "LoQ1pUNEb7XR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25,), dtype=int64, numpy=\n",
       "array([ 2,  9, 14, 39,  2, 12, 21,  5, 39,  1, 20, 39,  6, 39,  6, 15, 21,\n",
       "       18, 39, 16, 12,  5,  1, 19,  5])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfe004dd-8291-45c7-bbf1-b850990da564",
   "metadata": {
    "id": "bfe004dd-8291-45c7-bbf1-b850990da564"
   },
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3184a1-6b02-4b4f-84a8-a0a65f951ea2",
   "metadata": {
    "id": "0e3184a1-6b02-4b4f-84a8-a0a65f951ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28fa3a390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(frames[4]) # frames of video (0 ~ 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7ec0833-d54b-4073-84cf-92d011c60ec1",
   "metadata": {
    "id": "d7ec0833-d54b-4073-84cf-92d011c60ec1"
   },
   "outputs": [],
   "source": [
    "# alignments #[' ', 'bin', ' ', 'blue', ' ', 'at', ' ', 'l', ' ', 'six', ' ', 'now']를 char_to_num을 이용해 숫자로 변환 한 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "255302a9-8a03-4164-a892-e48077b6aa9e",
   "metadata": {
    "id": "255302a9-8a03-4164-a892-e48077b6aa9e"
   },
   "outputs": [],
   "source": [
    "# alignments.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3823e59d-0919-4fba-b9d2-966ba7f59524",
   "metadata": {
    "id": "3823e59d-0919-4fba-b9d2-966ba7f59524"
   },
   "outputs": [],
   "source": [
    "# num_to_char(alignments.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eefdf11-8a49-4617-a73a-3765a03d352f",
   "metadata": {
    "id": "4eefdf11-8a49-4617-a73a-3765a03d352f"
   },
   "outputs": [],
   "source": [
    "# num_to_char(alignments.numpy()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bd43f1d-f263-475f-ba38-7683909da32b",
   "metadata": {
    "id": "6bd43f1d-f263-475f-ba38-7683909da32b"
   },
   "outputs": [],
   "source": [
    "# [bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe1ad370-b287-4b46-85a2-7c45b0bd9b10",
   "metadata": {
    "id": "fe1ad370-b287-4b46-85a2-7c45b0bd9b10"
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
   "metadata": {
    "id": "6871031a-b0ba-4c76-a852-f6329b0f2606",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
   "metadata": {
    "id": "c40a7eb4-0c3e-4eab-9291-5611cb68ce08",
    "tags": []
   },
   "source": [
    "# 2. Create Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bd1a6431-c19d-4315-b27e-95a40e644507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 하위 폴더를 돌며 '._' 로 시작하는 파일 지우기\n",
    "# import os\n",
    "\n",
    "# def remove_dotunderscore_files(root_folder):\n",
    "#     for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "#         for filename in filenames:\n",
    "#             if filename.startswith('._'):\n",
    "#                 file_path = os.path.join(foldername, filename)\n",
    "#                 os.remove(file_path)\n",
    "#                 print(f'Removed: {file_path}')\n",
    "\n",
    "# # 사용 예시\n",
    "# root_directory = './data/150_less_intersect'\n",
    "# remove_dotunderscore_files(root_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7686355d-45aa-4c85-ad9c-053e6a9b4d81",
   "metadata": {
    "id": "7686355d-45aa-4c85-ad9c-053e6a9b4d81",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "Yufekosh-Z9F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yufekosh-Z9F",
    "outputId": "c28a0366-68c5-4fa5-c8e2-e89a13a28df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "./data/111/s5/bbaz1s.mpg\n",
      "./data/111/s5/bbar7s.mpg\n",
      "./data/111/s3/bbaz2n.mpg\n",
      "./data/111/s1/bbaf5a.mpg\n",
      "./data/111/s2/bbal8a.mpg\n",
      "./data/111/s1/bbal6n.mpg\n",
      "./data/111/s2/bbal7p.mpg\n",
      "./data/111/s2/bbar9n.mpg\n",
      "./data/111/s5/bbar9a.mpg\n",
      "./data/111/s2/bbal6s.mpg\n",
      "./data/111/s5/bbaz2p.mpg\n",
      "./data/111/s3/bbas1a.mpg\n",
      "./data/111/s5/bbar8p.mpg\n",
      "./data/111/s1/bbaf4p.mpg\n",
      "./data/111/s3/bbaszp.mpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 기본 디렉토리 경로\n",
    "# base_dir = './data/150_less_intersect/'\n",
    "base_dir = './data/111/'\n",
    "\n",
    "# 서브 디렉토리 목록 (s1부터 s10까지)\n",
    "# s8의 데이터는 문제가 많아서 제외\n",
    "sub_directories = [\n",
    "    # 's2_'\n",
    "    's1', 's2', 's3', 's5'\n",
    "    # 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's9', 's10', 's11',\n",
    "    # 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20',\n",
    "    # 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's30',\n",
    "    # 's31', 's32', 's33', 's34'\n",
    "    ]\n",
    "\n",
    "# 모든 데이터셋을 담을 변수\n",
    "all_data = tf.data.Dataset.list_files([os.path.join(base_dir, sub_dir, '*.mpg') for sub_dir in sub_directories])\n",
    "# all_data = all_data.repeat(100) # 데이터 셋을 epoch 만큼 반복 시켜 늘림\n",
    "print(len(all_data))\n",
    "\n",
    "# 데이터를 메모리에 미리 로드\n",
    "# all_data = all_data.cache()\n",
    "\n",
    "\n",
    "# 데이터셋 확인\n",
    "for file_path in all_data:\n",
    "    print(file_path.numpy().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3d9c5e9-8345-411e-acb0-074a7694e154",
   "metadata": {
    "id": "d3d9c5e9-8345-411e-acb0-074a7694e154",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = all_data\n",
    "data_len = len(data)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "data = data.shuffle(int(data_len / 10), reshuffle_each_iteration=False) # shuffle for 10 %\n",
    "data = data.map(mappable_function) # load_data -> load_video/load_align 를 거쳐 입모양 부분만 뽑아낸 데이터들이 된다\n",
    "data = data.padded_batch(batch_size, padded_shapes=([75,None,None,None],[40])) # batch_size 개씩 묶어 배치를 구성. 전체 데이터의 수가 1000 / 2 = 500 이 된다. [40]: .align파일의 마지막 열에 있는 단어와 철자들의 합은 40이하이면 되고 모자란 경우 0으로 패딩된다\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Added for split\n",
    "train_num = int(data_len / batch_size * 0.8)\n",
    "train = data.take(train_num)\n",
    "test = data.skip(train_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63443e18-1b24-499c-8efb-050d7d3f0269",
   "metadata": {
    "id": "63443e18-1b24-499c-8efb-050d7d3f0269",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames, alignments = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "p2ROUZyOg3JA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2ROUZyOg3JA",
    "outputId": "b0616512-47a9-4d4d-8ec4-1fbdb44b7497"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "kk_1KR9lg5vF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kk_1KR9lg5vF",
    "outputId": "b32b39a0-1bce-4b94-b0ab-0fb4390960d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bea067a3-5bf2-4328-a604-e9a2f951a66f",
   "metadata": {
    "id": "bea067a3-5bf2-4328-a604-e9a2f951a66f"
   },
   "outputs": [],
   "source": [
    "# print(\"Frames Shape:\", frames.shape)\n",
    "# print(\"Alignments Shape:\", alignments.shape)\n",
    "\n",
    "# 만약 값이 너무 크다면, 첫 번째 프레임과 정렬 정보의 일부를 출력해 보세요.\n",
    "# print(\"First Frame:\", frames[0])\n",
    "# print(\"First Alignment:\", alignments[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "07a9aa19-5c53-493c-aa79-c33a366e5220",
   "metadata": {
    "id": "07a9aa19-5c53-493c-aa79-c33a366e5220"
   },
   "outputs": [],
   "source": [
    "# len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e58c6bba-347c-4a91-8086-f90c60f56dc9",
   "metadata": {
    "id": "e58c6bba-347c-4a91-8086-f90c60f56dc9"
   },
   "outputs": [],
   "source": [
    "# len(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
   "metadata": {
    "id": "5cf2d676-93a9-434c-b3c7-bdcc2577b2e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
   "metadata": {
    "id": "efa6cd46-7079-46c0-b45b-832f339f6cb0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val = sample.next(); val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "acf5eb4f-a0da-4a9a-bf24-af13e9cc2fbe",
   "metadata": {
    "id": "acf5eb4f-a0da-4a9a-bf24-af13e9cc2fbe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imageio.mimsave('./animation.gif', val[0][0], fps=10)\n",
    "# imageio.mimsave('./animation.gif', val[0][0].squeeze(), fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c33a87a2-d5e0-4ec9-b174-73ebf41bf03a",
   "metadata": {
    "id": "c33a87a2-d5e0-4ec9-b174-73ebf41bf03a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0:videos(1:alignments), 0: 1st video out of the batch(0~1),  0: return the first frame in the video(0~74)\n",
    "# plt.imshow(val[0][0][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46175921-6721-4138-b511-b50573a05567",
   "metadata": {
    "id": "46175921-6721-4138-b511-b50573a05567",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])\n",
    "# ([num_to_char(word) for word in val[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ce8a026-d112-4470-a848-89e626a76772",
   "metadata": {
    "id": "7ce8a026-d112-4470-a848-89e626a76772",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ([(word) for word in val[1][0]]) #마지막에 0의 연속이 들어간 것은 패딩의 효과 인듯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47733c-83bc-465c-b118-b198b492ad37",
   "metadata": {
    "id": "0f47733c-83bc-465c-b118-b198b492ad37",
    "tags": []
   },
   "source": [
    "# 3. Design the Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
   "metadata": {
    "id": "d8e9a497-191b-4842-afbd-26f5e13c43ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam #`tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`\n",
    "# from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3f753ed2-70b9-4236-8c1c-08ca065dc8bf",
   "metadata": {
    "id": "3f753ed2-70b9-4236-8c1c-08ca065dc8bf"
   },
   "outputs": [],
   "source": [
    "# data.as_numpy_iterator().next()[0][0].shape #[0: video][0: 배치 중 1번째]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9171056-a352-491a-9ed9-92b28ced268e",
   "metadata": {
    "id": "f9171056-a352-491a-9ed9-92b28ced268e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
    "model.add(Conv3D(128, 3, input_shape=(75,50,100,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78851825-2bcd-42a9-b7f2-28bb5a6bf43a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78851825-2bcd-42a9-b7f2-28bb5a6bf43a",
    "outputId": "0715cb32-fe41-45b7-d2e3-846d0cdfd657",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_3 (Conv3D)           (None, 75, 50, 100, 128   3584      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 75, 50, 100, 128   0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPoolin  (None, 75, 25, 50, 128)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 75, 25, 50, 256)   884992    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 75, 25, 50, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPoolin  (None, 75, 12, 25, 256)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 75, 12, 25, 75)    518475    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 75, 12, 25, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPoolin  (None, 75, 6, 12, 75)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 75, 5400)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 75, 256)           5661696   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 75, 256)           394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 75, 41)            10537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7473524 (28.51 MB)\n",
      "Trainable params: 7473524 (28.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f4b4798c-a65a-4c47-9e2a-3b09dc98d320",
   "metadata": {
    "id": "f4b4798c-a65a-4c47-9e2a-3b09dc98d320"
   },
   "outputs": [],
   "source": [
    "# 5*17*75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5c2eae0-c359-41a4-97a0-75c44dccb7d1",
   "metadata": {
    "id": "e5c2eae0-c359-41a4-97a0-75c44dccb7d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yhat = model.predict(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ffdc7319-0d69-4f7e-a6d4-ce72deb81c0b",
   "metadata": {
    "id": "ffdc7319-0d69-4f7e-a6d4-ce72deb81c0b"
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8d15c83-c18e-4812-a3e0-6d4b2eb3d302",
   "metadata": {
    "id": "a8d15c83-c18e-4812-a3e0-6d4b2eb3d302"
   },
   "outputs": [],
   "source": [
    "# tf.argmax(yhat[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ed47531-8317-4255-9a12-b757642258e6",
   "metadata": {
    "id": "6ed47531-8317-4255-9a12-b757642258e6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in yhat[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c37b9b9-5298-4038-9c33-5031d1b457f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c37b9b9-5298-4038-9c33-5031d1b457f0",
    "outputId": "ae515f10-318b-4e0a-e563-a4cf3a865a3e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 75, 50, 100, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98b316a4-5322-4782-8e36-4b3c1a696d85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98b316a4-5322-4782-8e36-4b3c1a696d85",
    "outputId": "e8a55eac-50da-405d-9234-d60e29af6e54",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 75, 41)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
   "metadata": {
    "id": "2ec02176-5c26-46c3-aff7-8352e6563c7d",
    "tags": []
   },
   "source": [
    "# 4. Setup Training Options and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
   "metadata": {
    "id": "ab015fd0-7fb4-4d5d-9fa2-30a05dbd515a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c564d5c9-db54-4e88-b311-9aeab7fb3e69",
   "metadata": {
    "id": "c564d5c9-db54-4e88-b311-9aeab7fb3e69",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a26dc3fc-a19c-4378-bd8c-e2b597a1d15c",
   "metadata": {
    "id": "a26dc3fc-a19c-4378-bd8c-e2b597a1d15c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, dataset_) -> None:\n",
    "        self.dataset = dataset_\n",
    "        print(self.dataset)\n",
    "        self.iterator = self.dataset.as_numpy_iterator()\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        try:\n",
    "            data = self.iterator.next()\n",
    "        except StopIteration:\n",
    "            self.iterator = self.dataset.as_numpy_iterator()\n",
    "            data = self.iterator.next()\n",
    "\n",
    "        yhat = self.model.predict(data[0])\n",
    "        print(\"yhat------------\")\n",
    "        print(yhat.shape)\n",
    "        print(yhat[0][0])\n",
    "        print(yhat.shape[0])\n",
    "        print(yhat)\n",
    "\n",
    "        batch_size_ = yhat.shape[0]\n",
    "        print(batch_size_)\n",
    "        print(f'len yhat: {len(yhat)}')\n",
    "\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75] * batch_size_, greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):\n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04be90d8-2482-46f9-b513-d5f4f8001c7e",
    "outputId": "5bfc3bb5-d4e4-4a94-87f8-47c1e924bc6d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_SkipDataset element_spec=(TensorSpec(shape=(None, 75, None, None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 40), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)\n",
    "checkpoint_callback = ModelCheckpoint(os.path.join(BASE_PATH + 'models','checkpoint'), monitor='loss', save_weights_only=True)\n",
    "schedule_callback = LearningRateScheduler(scheduler)\n",
    "example_callback = ProduceExample(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "PLoaICYFl_KP",
   "metadata": {
    "id": "PLoaICYFl_KP"
   },
   "outputs": [],
   "source": [
    "# spe = int(data_len / batch_size)\n",
    "# print(\"steps_per_epoch: \" + str(spe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "39e0ece1-1c23-4b61-9c8e-10318f032fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이스백 필터링 비활성화\n",
    "tf.debugging.disable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fe65e229-c79b-4b12-a7f5-7361ebf6d8d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5a625d61-76ec-494a-a3a0-551807c49373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn version:8901\n",
      "cuda version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# print(\"TensorFlow version:\", tf.__version__)\n",
    "# print(\"CUDA version:\", tf.test.is_built_with_cuda())\n",
    "# # print(\"cuDNN version:\", tf.test.is_built_with_cudnn())\n",
    "# print(\"cuDNN version:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "import torch\n",
    "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))\n",
    "print(\"cuda version: {}\".format(torch.version.cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "Iap7RVFEL-16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iap7RVFEL-16",
    "outputId": "ad12c36d-4f85-429a-c9cc-fffcb892b37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step- loss: 145.27\n",
      "yhat------------\n",
      "(1, 75, 41)\n",
      "[0.12711331 0.02156118 0.0136362  0.01578985 0.0089484  0.03196482\n",
      " 0.01600891 0.01528886 0.00669989 0.02624872 0.01891197 0.01368409\n",
      " 0.01689023 0.00875    0.02095333 0.01093556 0.01637145 0.0063411\n",
      " 0.01719608 0.00934279 0.01853528 0.01455476 0.01316627 0.01667923\n",
      " 0.01188049 0.0146223  0.01318373 0.01951752 0.01738991 0.01592041\n",
      " 0.02067847 0.01359251 0.01100194 0.01520738 0.01374613 0.01386682\n",
      " 0.00492892 0.01614203 0.01915943 0.04948559 0.24410415]\n",
      "1\n",
      "[[[0.12711331 0.02156118 0.0136362  ... 0.01915943 0.04948559 0.24410415]\n",
      "  [0.16658615 0.01757605 0.00920603 ... 0.0149662  0.04684325 0.34449688]\n",
      "  [0.1927869  0.01433236 0.00656892 ... 0.01175993 0.04178097 0.41264248]\n",
      "  ...\n",
      "  [0.25061366 0.01114927 0.00440194 ... 0.00850032 0.02471416 0.424556  ]\n",
      "  [0.23776174 0.0131365  0.00566237 ... 0.01033268 0.02583383 0.3617214 ]\n",
      "  [0.19888182 0.01607463 0.00781856 ... 0.01352879 0.02592107 0.27123713]]]\n",
      "1\n",
      "len yhat: 1\n",
      "Original: bin blue at l six soon\n",
      "Prediction: \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "12/12 [==============================] - 51s 4s/step - loss: 145.2773 - val_loss: 114.1601 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 634ms/steposs: 114.09\n",
      "yhat------------\n",
      "(1, 75, 41)\n",
      "[0.11330475 0.02063938 0.01890841 0.01236007 0.0079435  0.03866132\n",
      " 0.01436135 0.01246286 0.00558301 0.03773329 0.01750476 0.01061282\n",
      " 0.0238053  0.00796912 0.02738607 0.01196169 0.01512349 0.00482161\n",
      " 0.01508432 0.00736655 0.01842613 0.01438165 0.01301401 0.01496232\n",
      " 0.01023018 0.01383688 0.01199914 0.01466163 0.01352783 0.01336121\n",
      " 0.01546109 0.01507564 0.0081166  0.0170453  0.01146068 0.01004009\n",
      " 0.00488141 0.01260516 0.01961637 0.07676259 0.2469404 ]\n",
      "1\n",
      "[[[0.11330475 0.02063938 0.01890841 ... 0.01961637 0.07676259 0.2469404 ]\n",
      "  [0.14361538 0.01831733 0.01540095 ... 0.01696167 0.08067727 0.330077  ]\n",
      "  [0.17080918 0.01625513 0.01240474 ... 0.01450575 0.07785217 0.38312   ]\n",
      "  ...\n",
      "  [0.36667585 0.01252003 0.00595435 ... 0.0090873  0.03463974 0.35782138]\n",
      "  [0.35640937 0.01507128 0.0073753  ... 0.01110221 0.03401813 0.30620244]\n",
      "  [0.30419773 0.01916182 0.01003777 ... 0.01510027 0.03242036 0.23464857]]]\n",
      "1\n",
      "len yhat: 1\n",
      "Original: bin blue at z two please\n",
      "Prediction: \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "12/12 [==============================] - 48s 4s/step - loss: 114.0965 - val_loss: 105.8562 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      " 3/12 [======>.......................] - ETA: 29s - loss: 108.0400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/py3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train, validation_data=test, epochs=50, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccaa452-2c3b-4fee-bcc2-2223b4d21506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이스백 필터링 다시 활성화\n",
    "tf.debugging.enable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
   "metadata": {
    "id": "fa8ee94b-89f7-4733-8a0c-a86f86ff590a",
    "tags": []
   },
   "source": [
    "# 5. Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
   "metadata": {
    "id": "01fa7204-ce0e-49a8-8dbd-14fe5dfead40",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "# output = 'checkpoints.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('checkpoints.zip', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
   "metadata": {
    "id": "247f664d-3c87-4e96-946e-930dad0e1c2c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f2cd0435550>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(BASE_PATH + 'models/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f8d689f-b7bb-443c-9b88-e40c1d800828",
   "metadata": {
    "id": "7f8d689f-b7bb-443c-9b88-e40c1d800828",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
   "metadata": {
    "id": "38546dc2-bee9-4837-864b-8a884df40ad7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = test_data.next() # 첫 실행시 오래 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
   "metadata": {
    "id": "a43621f0-229d-4c0d-9554-9c3a3da9c61a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
   "metadata": {
    "id": "ea462999-f87e-4a7e-a057-5be7b6d8f7d5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'lay blue at q zero please'>]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
   "metadata": {
    "editable": true,
    "id": "82bd4c10-dd6e-411e-834b-2a3b43fd12c5",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75] * batch_size, greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
   "metadata": {
    "id": "5d68ac46-c90b-4eab-a709-f19aee569ff5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'lay blue at q zero please'>]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431",
   "metadata": {
    "id": "64622f98-e99b-4fed-a2cc-f0da82eb5431"
   },
   "source": [
    "# 6. Test on a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9358ea64-014f-4ef1-b30f-1f6a1e28f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤하게 선택된 .mpg 파일 경로: ./data/s30/bgbe8a.mpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def get_random_mpg_path(root_folder):\n",
    "    mpg_files = []\n",
    "    \n",
    "    # root_folder와 그 하위 폴더에서 .mpg 파일 찾기\n",
    "    for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.mpg'):\n",
    "                mpg_files.append(os.path.join(foldername, filename))\n",
    "    \n",
    "    # .mpg 파일이 없으면 None 반환\n",
    "    if not mpg_files:\n",
    "        return None\n",
    "    \n",
    "    # 랜덤하게 선택된 .mpg 파일 경로 반환\n",
    "    return random.choice(mpg_files)\n",
    "\n",
    "# 사용 예시\n",
    "root_folder = BASE_PATH + 'data/'\n",
    "random_mpg_path = get_random_mpg_path(root_folder)\n",
    "\n",
    "if random_mpg_path:\n",
    "    print(f'랜덤하게 선택된 .mpg 파일 경로: {random_mpg_path}')\n",
    "else:\n",
    "    print('폴더 안에 .mpg 파일이 없습니다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1cfca9b6-ebab-45e7-9574-11b5e5839ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/s34/pbil2s.mpg\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'place blue in l two soon'>]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. load random data (from s1 ~ s34, 훈련 데이터에 포함된 것도 있음. s12 부터는 훈련 데이터에 포함되지 않음.)\n",
    "test_path = get_random_mpg_path(root_folder)\n",
    "print(test_path)\n",
    "sample = load_test_data(tf.convert_to_tensor(test_path))\n",
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e91ba72d-5c01-45ea-892f-50ed5b79f39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'lay gree it u eive sleasn'>]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. predict\n",
    "yhat = model.predict(tf.expand_dims(sample[0], axis=0))\n",
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()\n",
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed636ef3-39d9-47ec-a3c6-7b21b035f3d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 프레임의 크기와 프레임 속도 설정\n",
    "width = 360\n",
    "height = 288\n",
    "fps = 25\n",
    "\n",
    "# 비디오 라이터 생성\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('./camout/output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# 실시간 영상 표시 및 저장\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # 프레임 크기 조정\n",
    "    frame = cv2.resize(frame, (width, height))\n",
    "    \n",
    "    # 영상 표시\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    # 영상 저장\n",
    "    out.write(frame)\n",
    "    \n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 작업 완료 후 리소스 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a8ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
